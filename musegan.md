---
description: >-
  Multi-track Sequential Generative Adversarial Networks for Symbolic Music
  Generation and Accompaniment
---

# MuseGAN

## Context

This is the follow up paper of MidiNet. The paper is originally published in 2017, and a later version of binary MuseGAN was published in 2018. It uses some ideas proposed in MidiNet including data representation and the use of GAN as basic network architecture. 

Here are some of the novelties of this paper

* Generate multi-track polyphonic music with temporal structure and multi-track interdependency.
* Extend the model to track-conditional generation.
* Intra-track and Inter-track objective measures for measuring real and generate music.

## Concept

For data representation and the basic of using GANs, please refer to the previous page on [MidiNet](https://xihuanzeng.gitbook.io/deep-music-generation/~/edit/drafts/-LHdnX-x_EdoESjygn6p/midinet).

### Modeling the Multi-track Interdependency



